### 3. 하드디스크관리, 사용자별 공간 할당
- 하드디스크 추가하기
    - IDE장치와 SCSI장치 구성
        - 메인보드의 IDE0, IDE1슬롯에는 각각 2개의 IDE장치를 장착 가능. 총 4개
        - 일반적으로 PC에서 쓰는 하드디스크나 CD/DVD가 IDE임
        - 서버용은 SCSI
        - 그래서 하드디스크를 추가하려면 IDE에 장치를 장착해야 한다. (보통 1:0 에는 DVD)
        - 나머지 IDE를 SCSI로 변경 가능하나 굳이 필요 없다.
        - VMWare는 SCSI 슬롯을 4개 지원한다. 0번은 0:0 ~ 0:15까지 15개(0:7 제외)의 하드디스크를 장착할 수 있다. 총 4개의 슬롯이므로 60개까지 가능
    - 하드디스크 추가
        - VMWare에서 Server를 클릭 후 Edit virtual machine settings 클릭
        - Hard Disk(SCSI)의 Advanced를 클릭하면 SCSI장치를 확인할 수 있다.
        - 리눅스에서는 처음 장착된 SCSI 하드의 이름을 /dev/sda라고 부른다. 추가로 하드가 장착되면 /dev/sdb, /dev/sdc 등등이 된다.
        - 그리고 각 장치마다 파티션을 나눌 수 있으면 이 파티션은 순차적으로 1, 2, 3, 4로 붙어서 /dev/sda1, sda2.. 등으로 불리우게 된다.
        - 기존에 SCSI를 하나 추가했었고, 이를 /와 swap으로 파티션을 나누었었다. 따라서, swap은 /dev/sda1, /는 /dev/sda2
        - 여기에 SCSI를 하나 더 추가한다. : 추가하면 /dev/sdb가 되고 파티션을 나누지 않는 다면 1개이므로 /dev/sdb1이 된다.
    - 실습
        - edit에서 add를 누르고 hard disk를 scsi로 추가하면 된다.
        - 되도록 이름을 지정할 때는 이름만으로 알 수 있도록 명시하는 것이 좋다.
        - 추가한 후 advanced를 확인하면 scsi 0:1로 추가되어 있을 것이다.
        - 부팅해보면 이제 우측 상단에 하드디스크 마크가 2개 있을 것.
    - 파티션
        - 하드디스크는 장착하면 단순 기계일 뿐이다.
        - 하드디스크를 사용하기 위해선 우선 파티션을 설정해야 한다.
        - 통째로 하나의 파티션으로 사용시에는 1개로 전체를 설정하는데, 2개로 나누려면 2개의 파티션을 설정하면 된다.
        - 파티션은 Primary partition과 Extended로 나뉘는데 1개의 하드는 4개의 Primary파티션으로 나눌 수 있다. 5개로 원한다면 3개까지 Primary로 하고 Extended를 설정한 다음 그 Extended를 2개의 Logical partition으로 나눈다.
    - 파티션 실습
        - 터미널을 켠다
        - fdisk /dev/sdb
        - Command : n (새로운 파티션 분할)
        - Select : p (primary)
        - Partition number : 1 (파티션 개수)
        - First Sector : enter (시작섹터 번호. 1개의 파티션만 나누는 경우 그냥 enter)
        - Last Sector : enter (마지막 섹터 번호)
        - Command : p (설정내용 확인)
        - Command : w (저장)
        - 할당된 파티션 장치의 이름은 /dev/sdb1이 된다.
        - mkfs -t /dev/sdb1 또는 mkfs.ext4 /dev/sdb1 : 파일시스템을 ext4형식으로 생성
        - 만약 새로운 폴더를 /mydata와 같이 만들고 그 안에 아무거나 넣게 되면 해당 파일은 /dev/sda1즉, root partition에 속하게 된다.
        - 따라서 /dev/sdb1에 파일을 저장하고 싶은 경우 우선 해당 하드디스크에 디렉토리를 마운트 시켜야 한다.
        - mount /dev/sdb1 /mydata 와 같이 진행한다.
        - 만약 umount하더라도 해당 파일이 없어지는 것은 아니고 그대로 저장은 되어 있다.
        - 만약 컴퓨터를 켤 때, /dev/sdb1이 항상 /mydata에 mount되어 있기를 바란다면, 아래와 같이 설정한다.
        - vi /etc/fstab
        - /dev/sdb1     /mydata     ext4    defaults    1 2
        - 이 /etc/fstab은 리눅스가 부팅시마다 자동으로 읽는 중요 파일이다.
        - 이 파일에는 마운트 정보가 수록되어 있으며, 글자가 틀리면 아예 부팅이 불가할 수 있다.
        - 6개의 필드는 각각 장치 이름, 마운트될 디렉터리, 파일 시스템, 속성, dump사용여부, 파일 시스템 체크 여부를 의미한다.
        - 파일시스템과 속성을 defaults로 하면 읽기/쓰기/실행 등의 작업이 대부분 가능하다. dump사용여부를 1로 하면 리눅스 dump명령어로 백업이 가능.
        - 파일시스템 체크 여부를 1 또는 2로 하면 부팅 시에 이 파티션을 체크하며, 1을 먼저 체크한다. 0이면 생략함(부팅 속도 상승 가능)
        - reboot하고 ls -l /mydata를 해보면 sdb1에 저장한 파일이 보일 것이다.
- 여러 개의 하드디스크를 하나처럼 사용하기
    - RAID
        - 서버 컴퓨터의 저장 장치 대부분은 하드웨어 RAID 또는 소프트웨어 RAID 방식을 사용
        - RAID : Redundant Array of Inexpensive/Independent Disks로 여러 개의 하드디스크를 하나의 하드처럼 사용하는 방식이다. 비용 절감하며 더 신뢰성도 높이고 성능까지 향상 가능
        - 종류는 크게 하드웨어 RAID, 소프트웨어 RAID로 나뉜다.
        - 하드웨어 RAID
            - 하드웨어 제조업체에서 여러 개의 하드디스크를 연결한 장비를 만들어서 그 자체를 공급하는 것
            - 안정적이고 각 제조업체의 기술 지원을 받아 많이 선호됨
            - 대개 하드웨어 RAID는 고가는 SA-SCSI, 중저가는 SATA를 사용해 만든다.
        - 소프트웨어 RAID
            - 고가인 하드웨어의 대안으로 하드디스크만 여러 개 있으면 운영체제에서 지원하는 방식으로 RAID를 구성하는 방법을 의미함
            - 신뢰성이나 속도가 떨어지지만, 저렴하며 좀 더 안전하ㅔㄱ 데이터를 저장 가능하다.
        - RAID 레벨
            - 기본적으로 구성 방식에 따라, Linear RAID, RAID 0 ~ 5 까지 7개로 구분된다.
            - 실무에서는 ㅈ로 Linear, 0, 1, 5와 5의 변형인 6, 1+0(1과 0의 혼합)을 주로 사용한다.
            - 단순 볼륨 : 하드디스크 하나를 하나의 볼륨으로 사용. RAID방식에는 사용 x. 이미 해본 방식
            - Linear RAID, RAID 0 : 최소 2개의 하드디스크 필요. 2개 이상의 하드를 1개의 볼륨으로 사용. 저장방식에 차이. Linear는 앞의 하드가 다 채워지면 뒤를 사용. RAID 0 은 모든 하드를 사용해 저장.
                - 이와 같이 하드디스크 여러 개에 동시에 저장하는 방식이 stripping인데, 이 방식이 Linear보다 더 빠르다. 그래서 RAID 0 방식이 가장 빠름. 공간 효율도 더 좋다.
                - 문제는 여러 개에 동시에 저장하다 보니 하나가 망가지면 사실상 모든 데이터를 잃는 것과 같다는 것이다.
                - 그래서, RAID 0을 쓰는 것은 빠른 성능이 필요하되, 전부 잃어도 큰 문제는 없는 자료를 저장시에 적합하다.
                - 반면에 Linear는 각각 저장하기 때문에 총공간에 대한 효율이 가장 좋다.
            - RAID 1 : 미러링방식이다. 똑같은 데이터의 거울을 만들어 놓는다는 것. 그래서, 같은 내용을 2번 저장. 총 용량의 절반만 사용.
                - 장점은 하나가 고장나도 데이터 손상이 없다는 것. 이것이 결함허용
                - 단점은 실제 계획보다 2배 큰 용량이 필요하다는 것..
                - 즉, 비용을 감당할 만큼 중요한 데이터의 경우에 사용함.
            - RAID 5 : 1처럼 데이터 안정성을 가지면서도, 0처럼 공간 효율성도 좋은 방식을 어느정도 포용한 것. 최소 3개 이상의 하드가 있어야 구성됨. 대개는 5개 이상으로 함.
                - 하드에 이상이 발생시 패리티를 이용해 데이터 복구.
                - 짝수패리티를 이용하는 경우 데이터를 저장할 때 패리티 공간을 하나 남겨둔 다음, 전체의 덧셈이 짝수가 되도록 유추할 수 있는 방식을 의미함.
                - 이에 따라 결함도 허용되고, 공간 효율도 괜찮음. 패리티로 사용하는 부분을 제외하고는 전부 사용
            - RAID 6 : 허나, RAID 5도 2개가 동시에 고장나면?, 노답이다. 그래서 RAID6는 2개의 패리티를 쓴다 ㅋㅋㅋㅋ
                - 이에 따라, 공간 효율은 좀 낮더라도 신뢰도는 더욱 높아진다.
            - 이외 : 1+0방식의 경우, 1의 미러링으로 구성한 데이터를 다시 0으로 구성하는 것을 의미.
    - 실습
        - 9개의 하드디스크를 준비하자.
        - 알아서 9개를 만든다.(1만 2GB, 나머지는 1GB)
        - 각각을 partition을 나눈다.
        - ls -l /dev/sd*로 해보면 확인 
        - 각 파티션 설정 : 아까와 같지만 이번에는 RAID로 설정하기 위해서 파일시스템 유형을 직접 선택한다. Last Sector이후에 Command : t로 하고 fd 입력후 p, w로 저장
            - fd는 linux raid autodetect임.
        - 다 만들었으면 ls -l /dev/sd*로 확인해본다.
        - halt -p로 끄고 해당 내용을 backup하자
        - Linear RAID 구축
            - 우선 선처리작업을 확인한다. fdisk -l /dev/sdb; fdisk -l /dev/sdc : -l을 이용해 파티션 상태를 출력함
            - mdadm명령어로 실제 RAID구축 : `mdadm --create /dev/md9 --level=linear --raid-devices=2 /dev/sdb1 /dev/sdc1` 로 RAID를 생성(md9은 임의로 지정한 이름이다.)
                - --create는 RAID를 md9장치에 생성
                - --level=linear는  Linear RAID를 지정. 0은 RAID 0, 1은 RAID 1
                - --raid-devices=2 /dev/sdb1 /dev/sdc1 은 2개 하드를 사용.
                - mdadm --stop /dev/md9 : RAID장치인 md9를 중지
                - mdadm --run /dev/md9 : 중지된 RAID 가동
                - mdadm --detail /dev/md9 : md9의 상세한 내역 출력
            - `mdadm --detail --scan` 으로 RAID확인
            - `mkfs.ext4 /dev/md9`또는 `mkfs -t ext4 /dev/md9`으로 파일 시스템 생성
            - `mkdir raidLinear`로 마운트할 디렉터리 생성. `mount /dev/md9 /raidLinear`로 마운트
            - `df`명령어로 확인 가능
        - RAID 0 구축
            - 앞과 비슷함. 대신 mdadm명령어 사용시 --level=0이다.
            - /dev/sdd, /dev/sde로 만들어본다.
            - 추가로 자동으로 mount되도록 /etc/fstab에 추가한다. : `/dev/md0 /raid0 ext4 defaults 0 1`
        - RAID 1 구축
            - 0과 같음. level이 다름
        - RAID 5 구축
            - 1과 같음 하지만 하드 최소 3개 이상
            - 경고 메세지는 무시해도 된다.
        - 다 만들었으면 꼭 backup을 해둔다.
    - 고장내고 문제발생 해결 실습 
        - df명령어로 다들 잘 mount되어 있는지 확인한다.
        - halt -p로 끄고 나서 edit에서 3 ,5, 7, 9를 삭제하자. 이는 하드가 고장난것과 같다.
        - 다시 boot하면 우측 상단에 하드디스크들에서 말풍선으로 고장상태를 알려준다.
        - 그러다가 부팅 도중 응급모드로 전환될 것이다.
        - root로 접속하고 ls -l /dev/sd*를 해보면 전부 있지 않은 것을 확인가능하다.
        - df로 확인하면 기존의 Linear, 0, 1, 5가 확인되지 않는다.
        - 결함이 허용되는 RAID1과 RAID5를 가동해보자 : `mdadm --run /dev/md1`으로 1만 가동한다.
        - system-fsck~라는 메시지가 나오면 enter
        - 이 때, df를 해보면 md1이 잘 나오는 것을 확인 가능. mdadm --detail /dev/md1을 확인해보면 sdd1만 작동하는 것을 알 수 있다.
        - 마찬가지로 5도 가동
        - 0과 Linear는 재가동이 불가하다. 1개의 하드디스크로는 아예 작동하지 않기 때문이다.
        - 이제, /etc/fstab에서 0과 Linear는 주석처리하고 재부팅해보자
        - 그러면 md1과 md5만 잘 작동하는 것을 알 수 있다.
    - 복구
        - 새로이 하드디스크를 edit에서 만들고 부팅한다.
        - 다시 x윈도가 나오지만 복구된 것은 아니다.
        - fdisk명령을 통해서 c, e, g, i의 파티션을 설정한다.
        - Linear와 0같은 경우에는 아예 새로 만들어야 한다. stop시키고 mdadm --create를 통해서 다시 설정한다.
        - 1과 5같은 경우는 하드 하나가 빠졌을 뿐 잘 작동하기 때문에 다음과 같이 하드디스크만 추가한다.
        - `mdadm /dev/md1 --add /dev/sdg1`
        - `mdadm /dev/md5 --add /dev/sdi1`
        - detail명령어로 잘 작동하는지 확인하고 /etc/fstab에서 주석을 풀고 재부팅 해보자
        - 이제는 정상적인 부팅이 가능하다.
        - ls 명령어로 raid0를 확인시 당연히 testFile은 보이지 않아야 한다.
        - 만약 보인다고 해도 그것은 완벽한 파일이 아니다.. 따라서 mkfs로 포맷하자.(umount로 마운트를 제거한 후 해야함)
        - 또한, Linear쪽에서 testFile이 보일 수도 있다. 이것은 운이 좋게도, 데이터가 2GB였던 곳에 저장한 상태에서 1GB짜리 후순위 하드를 고장냈기 때문이다. 이를 항상 기대해선 안된다..